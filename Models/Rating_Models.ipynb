{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n[nltk_data]     /Users/sanyas/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to /Users/sanyas/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /Users/sanyas/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import re # regular expression libary.\n",
    "import nltk # Natural Language toolkit\n",
    "nltk.download(\"stopwords\")  #downloading stopwords\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize,sent_tokenize\n",
    "nltk.download('wordnet')\n",
    "import nltk as nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_nlp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                              Review  Rating\n",
       "0  nice hotel expensive parking got good deal sta...       4\n",
       "1  ok nothing special charge diamond member hilto...       2\n",
       "2  nice rooms not 4* experience hotel monaco seat...       3\n",
       "3  unique, great stay, wonderful time hotel monac...       5\n",
       "4  great stay great stay, went seahawk game aweso...       5"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Review</th>\n      <th>Rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>nice hotel expensive parking got good deal sta...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>ok nothing special charge diamond member hilto...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>nice rooms not 4* experience hotel monaco seat...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>unique, great stay, wonderful time hotel monac...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>great stay great stay, went seahawk game aweso...</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = df.index\n",
    "df['random_number'] = np.random.randn(len(index))\n",
    "train = df[df['random_number'] <= 0.8]\n",
    "test = df[df['random_number'] > 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count vectorizer:\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "train_matrix = vectorizer.fit_transform(train['Review'])\n",
    "test_matrix = vectorizer.transform(test['Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_matrix\n",
    "X_test = test_matrix\n",
    "y_train = train['Rating']\n",
    "y_test = test['Rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lr = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 164,   55,   13,    5,    2],\n",
       "       [  76,  124,   69,   24,    9],\n",
       "       [  25,   92,  144,   72,   35],\n",
       "       [  10,   87,  197,  666,  427],\n",
       "       [  12,   29,   66,  541, 1474]])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# find accuracy, precision, recall:\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "new = np.asarray(y_test)\n",
    "confusion_matrix(predict_lr,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of Random Forest Classifier: 0.5821638750565867\n              precision    recall  f1-score   support\n\n           1       0.57      0.69      0.62       239\n           2       0.32      0.41      0.36       302\n           3       0.29      0.39      0.34       368\n           4       0.51      0.48      0.49      1387\n           5       0.76      0.69      0.72      2122\n\n    accuracy                           0.58      4418\n   macro avg       0.49      0.53      0.51      4418\nweighted avg       0.60      0.58      0.59      4418\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy of Random Forest Classifier:\",accuracy_score(y_test, predict_lr))\n",
    "print(classification_report(predict_lr,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model_gn = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_mn = model_gn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 107,   18,    2,    0,    1],\n",
       "       [ 133,   94,   27,    8,    1],\n",
       "       [  11,   20,   11,    1,    0],\n",
       "       [  67,  210,  327,  621,  298],\n",
       "       [  18,   26,   92,  631, 1621]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "new = np.asarray(y_test)\n",
    "confusion_matrix(predict_mn,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest Classifier: 0.5647871116225547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.32      0.84      0.46       128\n",
      "           2       0.26      0.36      0.30       263\n",
      "           3       0.02      0.26      0.04        43\n",
      "           4       0.49      0.41      0.45      1523\n",
      "           5       0.84      0.68      0.75      2388\n",
      "\n",
      "    accuracy                           0.56      4345\n",
      "   macro avg       0.39      0.51      0.40      4345\n",
      "weighted avg       0.66      0.56      0.60      4345\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Random Forest Classifier:\",accuracy_score(y_test, predict_mn))\n",
    "print(classification_report(predict_mn,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest Classifier: 0.48584579976985043\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.21      0.73      0.32        94\n",
      "           2       0.05      0.33      0.09        60\n",
      "           3       0.01      0.20      0.01        15\n",
      "           4       0.19      0.36      0.25       668\n",
      "           5       0.93      0.51      0.65      3508\n",
      "\n",
      "    accuracy                           0.49      4345\n",
      "   macro avg       0.28      0.43      0.27      4345\n",
      "weighted avg       0.78      0.49      0.58      4345\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=50, n_estimators=20, criterion='entropy', min_samples_split=4).fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf=rf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy of Random Forest Classifier:\",accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_pred_rf,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                              Review  Rating  Review_length\n",
       "0  nice hotel expensive parking got good deal sta...       4             87\n",
       "1  ok nothing special charge diamond member hilto...       2            250\n",
       "2  nice rooms not 4* experience hotel monaco seat...       3            217\n",
       "3  unique, great stay, wonderful time hotel monac...       5             89\n",
       "4  great stay great stay, went seahawk game aweso...       5            191"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Review</th>\n      <th>Rating</th>\n      <th>Review_length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>nice hotel expensive parking got good deal sta...</td>\n      <td>4</td>\n      <td>87</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>ok nothing special charge diamond member hilto...</td>\n      <td>2</td>\n      <td>250</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>nice rooms not 4* experience hotel monaco seat...</td>\n      <td>3</td>\n      <td>217</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>unique, great stay, wonderful time hotel monac...</td>\n      <td>5</td>\n      <td>89</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>great stay great stay, went seahawk game aweso...</td>\n      <td>5</td>\n      <td>191</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "#keeping only relevant columns and calculating sentence lengths\n",
    "reviews = reviews[['Review', 'Rating']]\n",
    "reviews.columns = ['Review', 'Rating']\n",
    "reviews['Review_length'] = reviews['Review'].apply(lambda x: len(x.split()))\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing ratings to 0-numbering\n",
    "zero_numbering = {1:0, 2:1, 3:2, 4:3, 5:4}\n",
    "reviews['Rating'] = reviews['Rating'].apply(lambda x: zero_numbering[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "104.37582353228247"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "#mean sentence length\n",
    "np.mean(reviews['Review_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: torch in /Users/sanyas/opt/anaconda3/lib/python3.8/site-packages (1.7.1)\nRequirement already satisfied: typing-extensions in /Users/sanyas/opt/anaconda3/lib/python3.8/site-packages (from torch) (3.7.4.2)\nRequirement already satisfied: numpy in /Users/sanyas/opt/anaconda3/lib/python3.8/site-packages (from torch) (1.18.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-afc8b4582f71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#library imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "#library imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "import jovian\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import string\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = spacy\n",
    "def tokenize (text):\n",
    "    text = re.sub(r\"[^\\x00-\\x7F]+\", \" \", text)\n",
    "    regex = re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]') # remove punctuation and numbers\n",
    "    nopunct = regex.sub(\" \", text.lower())\n",
    "    return [token.text for token in tok.tokenizer(nopunct)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating vocabulary\n",
    "vocab2index = {\"\":0, \"UNK\":1}\n",
    "words = [\"\", \"UNK\"]\n",
    "for word in counts:\n",
    "    vocab2index[word] = len(words)\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(text, vocab2index, N=70):\n",
    "    tokenized = tokenize(text)\n",
    "    encoded = np.zeros(N, dtype=int)\n",
    "    enc1 = np.array([vocab2index.get(word, vocab2index[\"UNK\"]) for word in tokenized])\n",
    "    length = min(N, len(enc1))\n",
    "    encoded[:length] = enc1[:length]\n",
    "    return encoded, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}